{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6uFoJZUgswX",
        "outputId": "22494856-47a1-4437-f27c-db1e9a5cfc8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "#현재 위치 확인\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcY6hzhmg8ny",
        "outputId": "50169283-d5e4-4515-ffe5-b96cfa3a37b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'ACGPN'...\n",
            "remote: Enumerating objects: 165, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 165 (delta 21), reused 19 (delta 18), pack-reused 141\u001b[K\n",
            "Receiving objects: 100% (165/165), 303.15 KiB | 14.44 MiB/s, done.\n",
            "Resolving deltas: 100% (62/62), done.\n"
          ]
        }
      ],
      "source": [
        "#ACGPN 모델 파일 다운로드\n",
        "!git clone https://github.com/kairess/ACGPN.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8oyfgVOhRUA",
        "outputId": "6b0b9962-329c-437e-8b32-3949cbe15577"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/ACGPN\n"
          ]
        }
      ],
      "source": [
        "%cd ACGPN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhTTN5XzhUzt"
      },
      "source": [
        "dependencies 및 사전 파일 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6RtE1kihTZb",
        "outputId": "add60d9b-7596-446b-b965-4ad15943b753"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/146.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -U --no-cache-dir gdown --pre -qq\n",
        "!pip install ninja -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mD5n9YqThY2-"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import IPython\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "\n",
        "from predict_pose import generate_pose_keypoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4m7E7olRhfkg"
      },
      "outputs": [],
      "source": [
        "#모델을 돌리기 위한 파일 준비\n",
        "!mkdir Data_preprocessing/test_color\n",
        "!mkdir Data_preprocessing/test_colormask\n",
        "!mkdir Data_preprocessing/test_edge\n",
        "!mkdir Data_preprocessing/test_img\n",
        "!mkdir Data_preprocessing/test_label\n",
        "!mkdir Data_preprocessing/test_mask\n",
        "!mkdir Data_preprocessing/test_pose\n",
        "!mkdir inputs\n",
        "!mkdir inputs/img\n",
        "!mkdir inputs/cloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cH_8Y-MZhjNl",
        "outputId": "5b1e3a4d-5b39-4f0d-9de4-b164c788652e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/ACGPN\n"
          ]
        }
      ],
      "source": [
        "#현재 위치 확인\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_x6V3PUhkgI",
        "outputId": "7411bebb-9943-4a89-b972-d8c9375aa322"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Self-Correction-Human-Parsing-for-ACGPN'...\n",
            "remote: Enumerating objects: 769, done.\u001b[K\n",
            "remote: Counting objects: 100% (111/111), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 769 (delta 72), reused 62 (delta 62), pack-reused 658\u001b[K\n",
            "Receiving objects: 100% (769/769), 3.80 MiB | 22.22 MiB/s, done.\n",
            "Resolving deltas: 100% (189/189), done.\n"
          ]
        }
      ],
      "source": [
        "#휴먼 세그멘테이션 모델 파일 다운로드\n",
        "!git clone https://github.com/levindabhi/Self-Correction-Human-Parsing-for-ACGPN.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHfdI7zbh82M"
      },
      "source": [
        "사전학습 모델 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC5x1nvihmTk",
        "outputId": "fae50d0a-9a8c-4940-a8c5-9c86175fe8ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (uriginal): https://drive.google.com/uc?id=1hOHMFHEjhoJuLEQY0Ndurn5hfiA9mwko\n",
            "From (redirected): https://drive.google.com/uc?id=1hOHMFHEjhoJuLEQY0Ndurn5hfiA9mwko&confirm=t&uuid=ab204a21-8990-4034-80a9-16ec0176a810\n",
            "To: /content/ACGPN/pose/pose_iter_440000.caffemodel\n",
            "100% 209M/209M [00:07<00:00, 28.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "#포즈 예측 모델\n",
        "!gdown 1hOHMFHEjhoJuLEQY0Ndurn5hfiA9mwko -O pose/pose_iter_440000.caffemodel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "zI1eBvdTiBvV",
        "outputId": "7a1ba4e1-8332-4399-9e9d-e6a669e35a2a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (uriginal): https://drive.google.com/uc?id=1k4dllHpu0bdx38J7H28rVVLpU-kOHmnH\n",
            "From (redirected): https://drive.google.com/uc?id=1k4dllHpu0bdx38J7H28rVVLpU-kOHmnH&confirm=t&uuid=60a6b4f9-07fe-46b8-a597-8a68851d1a4f\n",
            "To: /content/ACGPN/lip_final.pth\n",
            "100%|██████████| 267M/267M [00:02<00:00, 111MB/s] \n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'lip_final.pth'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#휴먼 세그멘테이션 모델\n",
        "gdown.download('https://drive.google.com/uc?id=1k4dllHpu0bdx38J7H28rVVLpU-kOHmnH', 'lip_final.pth', quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mCiAvWyiFyl",
        "outputId": "f70e0ae6-ba85-4fe1-b152-e2be54fb2fc3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['000066_0.jpg']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#모델 데이터셋이 올바른 위치에 있는지 확인\n",
        "sorted(os.listdir('inputs/img'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muaA-TG4iTUx",
        "outputId": "d914c625-a86f-4434-cd8f-70af8d975a23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100% 1/1 [00:06<00:00,  6.80s/it]\n",
            "File saved at Data_preprocessing/test_pose/img_1681220345_keypoints.json\n"
          ]
        }
      ],
      "source": [
        "#전처리 할 모델 데이터 이름을 시간으로 지정\n",
        "img_name = f'img_{int(time.time())}.png'\n",
        "\n",
        "#전처리 할 모델 데이터의 파일 위치 확인\n",
        "img_path = os.path.join('inputs/img', sorted(os.listdir('inputs/img'))[0])\n",
        "\n",
        "#이미지 할당\n",
        "img = Image.open(img_path)\n",
        "\n",
        "#이미지 크기 변환 및 RGB 색공간으로 변환\n",
        "img = img.resize((192,256), Image.BICUBIC)\n",
        "\n",
        "#전처리를 위해 모델 이미지 파일의 위치값을 해당 파일 위치에 지정해준 모델 데이터 이름으로 지정\n",
        "img_path = os.path.join('Data_preprocessing/test_img', img_name)\n",
        "\n",
        "#지정해준 모델 이미지 파일의 위치값을 바탕으로 이미지 저장\n",
        "img.save(img_path)\n",
        "\n",
        "#전처리를 위해 휴먼 세그멘테이션 모델을 parser를 이용하여 돌림 \n",
        "#터미널에 입력되도록하는 코드로 변환해야함\n",
        "#parser는 데이터셋의 종류, 사전학습 모델 파일의 위치, 전처리 할 모델 이미지 위치, 전처리 후 이미지 저장할 위치\n",
        "!python3 Self-Correction-Human-Parsing-for-ACGPN/simple_extractor.py --dataset 'lip' --model-restore 'lip_final.pth' --input-dir 'Data_preprocessing/test_img' --output-dir 'Data_preprocessing/test_label'\n",
        "\n",
        "#모델 포즈 예측 모델을 돌리고 저장할 파일 위치와 파일 이름 형식을 지정\n",
        "pose_path = os.path.join('Data_preprocessing/test_pose', img_name.replace('.png', '_keypoints.json'))\n",
        "\n",
        "#모델 포즈 예측 모델을 전처리 할 모델 이미지 위치, 전처리 후 파일 위치를 받아서 돌리고 저장\n",
        "generate_pose_keypoints(img_path, pose_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "vh_bCWDjifYu",
        "outputId": "96028e25-e97c-44a8-c31a-f7b3c5d81757"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMAAAAEACAAAAADAKCbbAAAFVUlEQVR4nO2d227bMBBE14WDxHD6/x/aBHARA+2D7ViWKHFvQ67DnYdWCSSSh7PLW1WbKJVKpVIja4cp6Z9bsaJqXYtpxPDLpZRSN/h5K67arYwWJjg4sN4HLUyw17FdAtwEswOVHoCbYAWoNhBN4DMKdZQRgNG/YAsaOIAlsAE0mqy2tPco5Hi7+PQoTSZTH76XflmAQE4GLg486EhNnbA4UDTgpgcGoAWwUei4cu0t3DB6nFxtemUTcB44Tv7GESAnsiMR0REZPwRM4rk+DBVtafTFXH8lQG8lQG9ZAFAjo0itHIDBDh1Cgm7FRdvYDkRIY6MDTAIgaJMQ+tjhzl+aAOyAJ0hWAHZwoAjajUIggobDKIagCUDoYxXBCAmxwO5A58nMIYT4BAgLPHKgK4FPkdsnRB/3avxPeZ36ZJXg47EafwCnYXQtiua/948htxJLHkyaD7PAbSIreNBkgPWbiTvNB45LiTnBw8+wf2Tyzap7Iiz8uFbkDuI8LFwJCuH0JABE7yvZgAIALKfL2YxKgoZvO+yInsOBHyzg6UoqlUp1kmVgu7ztddY/rn50Ii3A/VU1bSu+S7Bh6N6Zc33Tbm9iUDgwb72u9lkpagQ5wLL3NZX7lEKKxVwhehQB5VMKkRygWM3eJSd0hTgtp4UIjoOAEGC9ZkmbVu5VYfltaNjV+wScuFpWUZyRxPltbdkwWq+8irBZhGIo9X57vbLA8X9Z3n9TvxXi/u2XhRC7/rILDgG4FAag1BTWw3IC1LnQIpAA0UNEMgekbZh0J/dRuQOojrmWfUbXgS0cXjz9gLPRkQDw4aBRMAfknRQMQK6BAGKmwEgOBFUCOEucadEAxEqA3kqA3mIDBJ2IB3IgqoYBiJoC4zgQVuEApLEaDkCqBOitBOitUQDCTsTDOBBXCdBbCeAu4YAXD0CoBOitBOitgACyYSgggEwJ0FsJ0FsJ0Fs8gLhbYh5A4PaPEUKRDRjDAY//MSiRyPEhHAitBOitkACSLM55oLcSACJB0MYEECgBeisBeisoAH8YCgrA1wgAoZdCQzjQRWzbowKwlQAespzbhACwEMQAKIibxQyAFgdz+jpCOGD5lK0QABbFBWAmQVwApsIAaJMgDIBWcQAWFvCSYIT9QIOJzNBHcUJoKRZWIACd04EAdAoNwImhSACqGIoBYBiFxI8aPyl4swlnn08u5T/mgHGt/+1kLEB3v+3jfhW1A4rYk9OnBhPRMob29aI9FjoKI/zWV4wPyptHzba2UdYfPxVvaOMAtsCKYswDd4nzKRrATHU/gwPUJQWA7W7elBWM4EDrlxZlevpNvXQiA+Lc1nN7otfL1V+G/QFz4Hy+tp9eXzdvJCKhAwcioi9Nozj6XlE/fJnuZ+UpRkRcl4iH648vMAKVuCF9uF/GIuDlwOFQvwek2pczcxyYtz6UBYFGodtiopq3DwoEsKJKDIUEkFgQEkAiFcBL/ZbT6aQ+6plpO4YYAL+1NQsJJrcLYggUQqfJn1hhAFq0/KoRkviPuNDT4gKnERyILTAAPoYQAPZWC/ZkIUOotgeYigMgH4bu0rghab/OAeyGRtR+HoDMAmMKzNtfWReFzIGpaus6HoAhC4x+VNelTAcsecxUkbS+ruaGEJ/Ace76ZOwL2DnQwIOL7q1mbWsE30c22ZltjaMLB95KdzGe40kwCv35urU70sGW7Lj/q76hb7gZIyIRwCUUIvU+0RNMZDU1AMAGVTowk7q7tQ+mA73VAgCaxQIATjtaT2MZQm5SWxcFQK0mAMjM8AVon8MZQt01FEA1wldvAObGUA4ApbfoP+wNqQpF9mPVAAAAAElFTkSuQmCC",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=L size=192x256 at 0x7F809F328670>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#결과 확인을 위해 전처리 된 모델 이미지 파일을 열어봄\n",
        "#성공한 겁니다.. 잘보면 회색보임\n",
        "Image.open(f'Data_preprocessing/test_label/{img_name}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aO3WcoIGjNSE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.15 64-bit ('dev')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "329e22198b68d8e60cd009d73b7185815e21aa24b6d9ff67db9978dd5b8ddb29"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
