{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wcgkZvbVrsn"
      },
      "source": [
        "# 모델에 필요한 파일 받기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVz3Nv8KVal2",
        "outputId": "8c74a2f0-d968-4564-cafa-26ce40a9bfcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "#현재 위치 확인\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d81mcKwgViSI",
        "outputId": "33745d14-9bb3-4838-d146-5ad90f05a971"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'ACGPN'...\n",
            "remote: Enumerating objects: 165, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 165 (delta 21), reused 19 (delta 18), pack-reused 141\u001b[K\n",
            "Receiving objects: 100% (165/165), 303.15 KiB | 3.29 MiB/s, done.\n",
            "Resolving deltas: 100% (62/62), done.\n"
          ]
        }
      ],
      "source": [
        "#ACGPN 모델 파일 다운로드\n",
        "!git clone https://github.com/kairess/ACGPN.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMpI-l40Vnc4",
        "outputId": "9e627fac-32e6-47a8-bf2b-59c8283c1648"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/ACGPN\n"
          ]
        }
      ],
      "source": [
        "#다운로드 받은 파일의 위치로 이동\n",
        "%cd ACGPN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vSFPFitVzvK"
      },
      "source": [
        "# dependencies 및 사전 파일 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNrXhTpKVyVb",
        "outputId": "7e3e7da4-a4e9-4d0d-a9e4-d361553b4ef7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/146.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -U --no-cache-dir gdown --pre -qq\n",
        "!pip install ninja -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Z29mLLJ9V47A"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import IPython\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "\n",
        "from predict_pose import generate_pose_keypoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "avsTo1jjV8n2"
      },
      "outputs": [],
      "source": [
        "#모델을 돌리기 위한 파일 준비\n",
        "!mkdir Data_preprocessing/test_color\n",
        "!mkdir Data_preprocessing/test_colormask\n",
        "!mkdir Data_preprocessing/test_edge\n",
        "!mkdir Data_preprocessing/test_img\n",
        "!mkdir Data_preprocessing/test_label\n",
        "!mkdir Data_preprocessing/test_mask\n",
        "!mkdir Data_preprocessing/test_pose\n",
        "!mkdir inputs\n",
        "!mkdir inputs/img\n",
        "!mkdir inputs/cloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JS2JlsWYV_rG",
        "outputId": "37512c79-3e4d-41e4-b25e-0f83e03c49fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/ACGPN\n"
          ]
        }
      ],
      "source": [
        "#현재 위치 확인\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49WwTnwiWCK7",
        "outputId": "452e45f4-4db9-42ca-e49a-b43fa2e00a9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Self-Correction-Human-Parsing-for-ACGPN'...\n",
            "remote: Enumerating objects: 769, done.\u001b[K\n",
            "remote: Counting objects: 100% (111/111), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 769 (delta 72), reused 62 (delta 62), pack-reused 658\u001b[K\n",
            "Receiving objects: 100% (769/769), 3.80 MiB | 18.26 MiB/s, done.\n",
            "Resolving deltas: 100% (189/189), done.\n",
            "Cloning into 'U-2-Net'...\n",
            "remote: Enumerating objects: 822, done.\u001b[K\n",
            "remote: Total 822 (delta 0), reused 0 (delta 0), pack-reused 822\u001b[K\n",
            "Receiving objects: 100% (822/822), 30.72 MiB | 38.59 MiB/s, done.\n",
            "Resolving deltas: 100% (379/379), done.\n"
          ]
        }
      ],
      "source": [
        "#휴먼 세그멘테이션 모델 파일 다운로드\n",
        "!git clone https://github.com/levindabhi/Self-Correction-Human-Parsing-for-ACGPN.git\n",
        "#옷 마스킹 모델 파일 다운로드\n",
        "!git clone https://github.com/levindabhi/U-2-Net.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuAjjwc-WEpM"
      },
      "source": [
        "# 사전학습된 모델 다운로드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWLZLYkbWMAz"
      },
      "source": [
        "# 포즈 예측 모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fhz9rATaWDf5",
        "outputId": "0e366ddc-d141-4cca-bedf-d416201e509b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (uriginal): https://drive.google.com/uc?id=1hOHMFHEjhoJuLEQY0Ndurn5hfiA9mwko\n",
            "From (redirected): https://drive.google.com/uc?id=1hOHMFHEjhoJuLEQY0Ndurn5hfiA9mwko&confirm=t&uuid=07038ecb-3bc8-4a0f-85e6-344b9a1440e6\n",
            "To: /content/ACGPN/pose/pose_iter_440000.caffemodel\n",
            "100% 209M/209M [00:04<00:00, 44.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1hOHMFHEjhoJuLEQY0Ndurn5hfiA9mwko -O pose/pose_iter_440000.caffemodel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRAhOeIUWOk4"
      },
      "source": [
        "# 휴먼 세그멘테이션 모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "hWO0zRmiWJk1",
        "outputId": "26b76087-d78e-4a93-dc7e-e13e77fdd578"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (uriginal): https://drive.google.com/uc?id=1k4dllHpu0bdx38J7H28rVVLpU-kOHmnH\n",
            "From (redirected): https://drive.google.com/uc?id=1k4dllHpu0bdx38J7H28rVVLpU-kOHmnH&confirm=t&uuid=81d302a2-b8ff-4350-bcc9-a94c5c93bb19\n",
            "To: /content/ACGPN/lip_final.pth\n",
            "100%|██████████| 267M/267M [00:06<00:00, 43.7MB/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'lip_final.pth'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gdown.download('https://drive.google.com/uc?id=1k4dllHpu0bdx38J7H28rVVLpU-kOHmnH', 'lip_final.pth', quiet=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2pn8E-SWQQK"
      },
      "source": [
        "# U-2-Net 모델 (옷 마스크 추출 모델)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncrkOSPOWLew",
        "outputId": "fdef495e-d9f1-4db9-97e8-205f64472d65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/ACGPN/U-2-Net\n",
            "mkdir: cannot create directory ‘saved_models’: File exists\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rbSTGKAE-MTxBYHd-51l2hMOQPT_7EPy\n",
            "To: /content/ACGPN/U-2-Net/saved_models/u2netp/u2netp.pth\n",
            "100% 4.68M/4.68M [00:00<00:00, 233MB/s]\n",
            "Downloading...\n",
            "From (uriginal): https://drive.google.com/uc?id=1ao1ovG1Qtx4b7EoskHXmi2E9rp5CHLcZ\n",
            "From (redirected): https://drive.google.com/uc?id=1ao1ovG1Qtx4b7EoskHXmi2E9rp5CHLcZ&confirm=t&uuid=d74d9582-b6a0-4000-a894-7312c19b3585\n",
            "To: /content/ACGPN/U-2-Net/saved_models/u2net/u2net.pth\n",
            "100% 176M/176M [00:00<00:00, 258MB/s]\n",
            "...load U2NEP---4.7 MB\n",
            "/content/ACGPN\n"
          ]
        }
      ],
      "source": [
        "#U-2-Net 모델을 돌릴 때 필요한 파일 준비를 위해 해당 모델 파일로 이동\n",
        "%cd U-2-Net\n",
        "\n",
        "#U-2-Net 모델에 필요한 파일 생성\n",
        "!mkdir saved_models\n",
        "!mkdir saved_models/u2net\n",
        "!mkdir saved_models/u2netp\n",
        "\n",
        "#사전 학습된 U-2-Net 모델 다운로드\n",
        "!gdown 1rbSTGKAE-MTxBYHd-51l2hMOQPT_7EPy -O saved_models/u2netp/u2netp.pth\n",
        "!gdown 1ao1ovG1Qtx4b7EoskHXmi2E9rp5CHLcZ -O saved_models/u2net/u2net.pth\n",
        "\n",
        "import u2net_load\n",
        "import u2net_run\n",
        "\n",
        "#로드하려면 쿠다 필요 (위치 확인용)\n",
        "u2net = u2net_load.model(model_name='u2netp')\n",
        "\n",
        "#U-2-Net 모델을 위한 파일 준비가 끝나면 부모 파일로 이동\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2lFpdZEWgV2"
      },
      "source": [
        "# ACGPN모델 (사진 합성 모델)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msZwaCghWavD",
        "outputId": "8701bd7e-896d-49fb-966e-9bce8837768c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (uriginal): https://drive.google.com/uc?id=1UWT6esQIU_d4tUm8cjxDKMhB8joQbrFx\n",
            "From (redirected): https://drive.google.com/uc?id=1UWT6esQIU_d4tUm8cjxDKMhB8joQbrFx&confirm=t&uuid=3a861a19-1cc4-4322-8a14-bebb220c1fa3\n",
            "To: /content/ACGPN/checkpoints/ACGPN_checkpoints.zip\n",
            "100%|██████████| 524M/524M [00:04<00:00, 113MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  checkpoints/ACGPN_checkpoints.zip\n",
            "   creating: checkpoints/label2city/\n",
            "  inflating: checkpoints/label2city/latest_net_G.pth  \n",
            "  inflating: checkpoints/label2city/latest_net_G1.pth  \n",
            "  inflating: checkpoints/label2city/latest_net_G2.pth  \n",
            "  inflating: checkpoints/label2city/latest_net_U.pth  \n",
            "  inflating: checkpoints/label2city/opt.txt  \n"
          ]
        }
      ],
      "source": [
        "#ACGPN 모델에 필요한 파일 생성\n",
        "!mkdir checkpoints\n",
        "\n",
        "#사전 학습된 ACGPN 모델 다운로드\n",
        "gdown.download('https://drive.google.com/uc?id=1UWT6esQIU_d4tUm8cjxDKMhB8joQbrFx', output='checkpoints/ACGPN_checkpoints.zip', quiet=False)\n",
        "\n",
        "#압축된 모델 파일 풀어서 전에 만든 파일위치에 넣어줌\n",
        "!unzip checkpoints/ACGPN_checkpoints.zip -d checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG9e2-LrWnbw"
      },
      "source": [
        "# 가설 1: 전처리부터 추론까지의 코드는 api안에 넣어준다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlY2FHweWlUR",
        "outputId": "241bcbce-7380-497f-9637-90a3514a816c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fastapi[standard]\n",
            "  Downloading fastapi-0.95.1-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: fastapi 0.95.1 does not provide the extra 'standard'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.9/dist-packages (from fastapi[standard]) (1.10.7)\n",
            "Collecting starlette<0.27.0,>=0.26.1\n",
            "  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2->fastapi[standard]) (4.5.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.9/dist-packages (from starlette<0.27.0,>=0.26.1->fastapi[standard]) (3.6.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.9/dist-packages (from anyio<5,>=3.4.0->starlette<0.27.0,>=0.26.1->fastapi[standard]) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.9/dist-packages (from anyio<5,>=3.4.0->starlette<0.27.0,>=0.26.1->fastapi[standard]) (3.4)\n",
            "Installing collected packages: starlette, fastapi\n",
            "Successfully installed fastapi-0.95.1 starlette-0.26.1\n"
          ]
        }
      ],
      "source": [
        "!pip install \"fastapi[standard]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "07e40XvcW5eO"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI, File, UploadFile\n",
        "from fastapi.responses import FileResponse, JSONResponse\n",
        "import os\n",
        "import time\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "app = FastAPI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qVbbmAeUW_ZU"
      },
      "outputs": [],
      "source": [
        "\n",
        "CLOTH_DIR = \"inputs/cloth\"\n",
        "MODEL_DIR = \"inputs/img\"\n",
        "PREPROCESS_DIR = \"Data_preprocessing\"\n",
        "COLOR_DIR = f\"{PREPROCESS_DIR}/test_color\"\n",
        "IMG_DIR = f\"{PREPROCESS_DIR}/test_img\"\n",
        "EDGE_DIR = f\"{PREPROCESS_DIR}/test_edge\"\n",
        "LABEL_DIR = f\"{PREPROCESS_DIR}/test_label\"\n",
        "POSE_DIR = f\"{PREPROCESS_DIR}/test_pose\"\n",
        "MODEL_RESTORE_PATH = \"lip_final.pth\"\n",
        "\n",
        "\n",
        "\n",
        "@app.post(\"/preprocess_image/cloth\")\n",
        "async def preprocess_clothimage():\n",
        "    cloth_dir = 'inputs/cloth'\n",
        "    assert os.path.isdir(cloth_dir), f\"{cloth_dir} is not a directory.\"\n",
        "\n",
        "    cloth_name = f'cloth_{int(time.time())}.png'\n",
        "\n",
        "    cloth_path = os.path.join(cloth_dir, sorted(os.listdir(cloth_dir))[0])\n",
        "\n",
        "    cloth = Image.open(cloth_path)\n",
        "\n",
        "    cloth = cloth.resize((192, 256), Image.BICUBIC).convert('RGB')\n",
        "\n",
        "    preprocessed_dir = 'Data_preprocessing/test_edge'\n",
        "    os.makedirs(preprocessed_dir, exist_ok=True)\n",
        "    preprocessed_path = os.path.join(preprocessed_dir, cloth_name)\n",
        "    cloth.save(preprocessed_path)\n",
        "\n",
        "    u2net_run.infer(u2net, 'Data_preprocessing/test_color', preprocessed_dir)\n",
        "\n",
        "    return FileResponse(preprocessed_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "LSfIGJXS9lC6"
      },
      "outputs": [],
      "source": [
        "#위에 적어놓음\n",
        "#from fastapi.responses import JSONResponse\n",
        "\n",
        "\n",
        "\n",
        "@app.post(\"/preprocess_image/img\")\n",
        "async def preprocess_modelimage():\n",
        "    img_dir = 'inputs/img'\n",
        "    assert os.path.isdir(img_dir), f\"{img_dir} is not a directory.\"\n",
        "\n",
        "    img_name = f'img_{int(time.time())}.png'\n",
        "\n",
        "    img_path = os.path.join(img_dir, sorted(os.listdir(img_dir))[0])\n",
        "\n",
        "    img = Image.open(img_path)\n",
        "\n",
        "    img = img.resize((192,256), Image.BICUBIC)\n",
        "\n",
        "    preprocessed_dir = 'Data_preprocessing/test_img'\n",
        "    os.makedirs(preprocessed_dir, exist_ok=True)\n",
        "    preprocessed_path = os.path.join(preprocessed_dir, img_name)\n",
        "    img.save(preprocessed_path)\n",
        "\n",
        "    seg_output_dir = 'Data_preprocessing/test_label'\n",
        "    os.makedirs(seg_output_dir, exist_ok=True)\n",
        "    seg_parser_args = f\"--dataset 'lip' --model-restore 'lip_final.pth' --input-dir '{preprocessed_dir}' --output-dir '{seg_output_dir}'\"\n",
        "    os.system(f\"python3 Self-Correction-Human-Parsing-for-ACGPN/simple_extractor.py {seg_parser_args}\")\n",
        "\n",
        "    pose_output_dir = 'Data_preprocessing/test_pose'\n",
        "    os.makedirs(pose_output_dir, exist_ok=True)\n",
        "    pose_path = os.path.join(pose_output_dir, img_name.replace('.png', '_keypoints.json'))\n",
        "    generate_pose_keypoints(preprocessed_path, pose_path)\n",
        "\n",
        "    seg_path = os.path.join(seg_output_dir, img_name)\n",
        "    pose_keypoints = load_pose_keypoints(pose_path)\n",
        "\n",
        "    combined_output_dir = 'Data_preprocessing/test_combine'\n",
        "    os.makedirs(combined_output_dir, exist_ok=True)\n",
        "    combine_images(seg_path, pose_keypoints, combined_output_dir)\n",
        "\n",
        "    combined_path = os.path.join(combined_output_dir, img_name)\n",
        "    with open(combined_path, mode='rb') as file:\n",
        "        return JSONResponse(content=file.read(), media_type=\"image/png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "N1VG4WGP_F-S"
      },
      "outputs": [],
      "source": [
        "@app.post(\"/predict\")\n",
        "async def predict_image():\n",
        "     with open('Data_preprocessing/test_pairs.txt', 'w') as f:\n",
        "          f.write(f'{img_name} {cloth_name}')\n",
        "          os.system(f\"python3 test.py\")\n",
        "\n",
        "\n",
        "     result_path = os.path.join('test', 'final', f'{img_name.split(\".\")[0]}_final.png')\n",
        "     with open(result_path, \"rb\") as f:\n",
        "        result_image = f.read()\n",
        "\n",
        "        return result_image "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IX9_Q8GUDGZx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
